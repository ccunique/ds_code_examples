{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccunique/ds_code_examples/blob/main/Graph/GNN/graph_env_setting_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYdn1woOS1n",
        "outputId": "ad446d4a-2631-485c-e89b-7593f57c592e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 25 01:41:02 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install torch, dgl, pyG, pygod"
      ],
      "metadata": {
        "id": "4WuNwv6VGQlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZIXNZPS3c1nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch 2.0.1+cu118\n",
        "need torch 2.0.1, if 2.1.0 dgl sparse will not work"
      ],
      "metadata": {
        "id": "oFXobbnhc4X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "RHYHGq--b9Iw",
        "outputId": "1b9817a1-fba3-4b31-d2c0-f44f43aac298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m494.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.2)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (9.4.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.7)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89989 sha256=41f4e3e72cb8586c0d3eaa00b1084f6c03ec8e8aeea54561c23e6279607729e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/2c/b6/3ed2983b1b44fe0dea1bb35234b09f2c22fb8ebb308679c922\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.1.0+cu118\n",
            "    Uninstalling torchaudio-2.1.0+cu118:\n",
            "      Successfully uninstalled torchaudio-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dgl"
      ],
      "metadata": {
        "id": "dkMJVA5SZR2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCLetsCA3GPy",
        "outputId": "c9e288c7-a5b5-421d-ab22-d565db4efeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/cu118/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu118/dgl-1.1.2%2Bcu118-cp310-cp310-manylinux1_x86_64.whl (91.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.3/91.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pyG series"
      ],
      "metadata": {
        "id": "mI8JeXTxZUHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "ib3BC4sBdnUv",
        "outputId": "82a84b21-2c75-4457-e8a0-ecacac637858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA-DEq903zu2",
        "outputId": "d9210e19-be85-4d16-f4f9-7a6b8b7c9ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.3.0%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (886 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.6/886.6 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.3.0+pt20cu118 torch_cluster-1.6.3+pt20cu118 torch_scatter-2.1.2+pt20cu118 torch_sparse-0.6.18+pt20cu118 torch_spline_conv-1.2.2+pt20cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pygod"
      ],
      "metadata": {
        "id": "TPeyxeHQZYg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS8k9btZFYqS",
        "outputId": "d3988d1c-8b19-4ed4-8ecd-dad2dab3cf97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygod\n",
            "  Downloading pygod-1.0.0.tar.gz (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pygod) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pygod) (1.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pygod) (3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pygod) (1.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pygod) (67.7.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pygod) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pygod) (3.2.0)\n",
            "Building wheels for collected packages: pygod\n",
            "  Building wheel for pygod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygod: filename=pygod-1.0.0-py3-none-any.whl size=70678 sha256=827245e209c42700e48679ac4fcfe9e3c95a7c3432aa21644b2d64a02d5797b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/4f/5e/d4a08c3476915cb8021462fe4129680c598ebce8b100f59ecf\n",
            "Successfully built pygod\n",
            "Installing collected packages: pygod\n",
            "Successfully installed pygod-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# version summary"
      ],
      "metadata": {
        "id": "YXLVjR1QZdcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# python >= 3.8\n",
        "sys.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lqShTG4e26c3",
        "outputId": "16b2bba2-1492-41f9-ee73-a7965fd39e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__name__,' version:', torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stLgQBB_7IlQ",
        "outputId": "a3aaa5de-dd51-4795-c8c5-ca8e41d410f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch  version: 2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "\n",
        "print(dgl.__name__,' version:', dgl.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU_Veh6W7Ica",
        "outputId": "08d8e47d-1a51-41c0-e7c4-d8fa03e372a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "dgl  version: 1.1.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch_geometric\n",
        "import pyg_lib\n",
        "import torch_scatter\n",
        "import torch_sparse\n",
        "import torch_cluster\n",
        "import torch_spline_conv\n",
        "import torch_geometric\n",
        "\n",
        "for lib in [pyg_lib, torch_scatter, torch_sparse, torch_cluster, torch_spline_conv, torch_geometric]:\n",
        "  print(lib.__name__,' version:', lib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcss0_3-6oBk",
        "outputId": "90c0aaa8-4ac9-4e9c-ee9d-563511c5a31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pyg_lib  version: 0.3.0+pt20cu118\n",
            "torch_scatter  version: 2.1.2+pt20cu118\n",
            "torch_sparse  version: 0.6.18+pt20cu118\n",
            "torch_cluster  version: 1.6.3+pt20cu118\n",
            "torch_spline_conv  version: 1.2.2+pt20cu118\n",
            "torch_geometric  version: 2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pygod\n",
        "\n",
        "print(pygod.__name__,' version:', pygod.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AliuTjKh9j29",
        "outputId": "1a11d865-60fc-440f-e818-c44a7b61fecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygod  version: 1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test DGL on gpu"
      ],
      "metadata": {
        "id": "rdOCT_M2ZBzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dgl sparse"
      ],
      "metadata": {
        "id": "I62uChrnk9_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test dglsp\n",
        "import dgl.sparse as dglsp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import dgl.sparse as dglsp\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "u, v = torch.tensor([0, 0, 0, 1, 1]), torch.tensor([1, 2, 3, 3, 3])\n",
        "g = dgl.graph((u, v))\n",
        "print(g)\n",
        "print(g.nodes())\n",
        "print(g.edges())\n",
        "print(g.edges(form='all'))\n",
        "g = dgl.graph((u, v), num_nodes=4)\n",
        "\n",
        "g.ndata['feat']=torch.tensor(np.random.rand(4,20), dtype=torch.float32)\n",
        "g.ndata[\"label\"]=torch.tensor(np.random.randint(0,2,(4,)))\n",
        "g.ndata['train_mask']=torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)\n",
        "g.ndata['val_mask']=torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)\n",
        "g.ndata['test_mask']=torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)\n",
        "g = dgl.add_self_loop(g)\n",
        "\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.W = nn.Linear(in_size, out_size)\n",
        "\n",
        "    def forward(self, A, X):\n",
        "        ########################################################################\n",
        "        # (HIGHLIGHT) Compute the symmetrically normalized adjacency matrix with\n",
        "        # Sparse Matrix API\n",
        "        ########################################################################\n",
        "        # I = dglsp.identity(A.shape).cuda() # why identity not move to cuda with model\n",
        "        I = dglsp.identity(A.shape, device=A.device) # identity need manully move to cuda based on A.device\n",
        "\n",
        "        A_hat = A + I\n",
        "        D_hat = dglsp.diag(A_hat.sum(0))\n",
        "        D_hat_invsqrt = D_hat ** -0.5\n",
        "        return D_hat_invsqrt @ A_hat @ D_hat_invsqrt @ self.W(X)\n",
        "\n",
        "# Create a GCN with the GCN layer.\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_size, out_size, hidden_size):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNLayer(in_size, hidden_size)\n",
        "        self.conv2 = GCNLayer(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, A, X):\n",
        "        X = self.conv1(A, X)\n",
        "        X = F.relu(X)\n",
        "        return self.conv2(A, X)\n",
        "\n",
        "\n",
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features = g.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    val_mask = g.ndata[\"val_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "    # Preprocess to get the adjacency matrix of the graph.\n",
        "    indices = torch.stack(g.edges())\n",
        "    N = g.num_nodes()\n",
        "    A = dglsp.spmatrix(indices, shape=(N, N))\n",
        "\n",
        "    for e in range(100):\n",
        "        # Forward\n",
        "        logits = model(A, features)\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that you should only compute the losses of the nodes in the training set.\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test accuracy.\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print(\n",
        "                f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
        "            )\n",
        "\n",
        "# # train on cpu\n",
        "# model = GCN(g.ndata[\"feat\"].shape[1], 2, 16)\n",
        "# train(g, model)\n",
        "\n",
        "# train on gpu\n",
        "g = g.to('cuda')\n",
        "model = GCN(g.ndata[\"feat\"].shape[1], 2, 16).to('cuda')\n",
        "train(g, model)\n"
      ],
      "metadata": {
        "id": "cPWDJBSMaugx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d144cef-5f06-451e-d7bd-d075a9949f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=4, num_edges=5,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={})\n",
            "tensor([0, 1, 2, 3])\n",
            "(tensor([0, 0, 0, 1, 1]), tensor([1, 2, 3, 3, 3]))\n",
            "(tensor([0, 0, 0, 1, 1]), tensor([1, 2, 3, 3, 3]), tensor([0, 1, 2, 3, 4]))\n",
            "In epoch 0, loss: 0.635, val acc: 0.750 (best 0.750), test acc: 0.667 (best 0.667)\n",
            "In epoch 5, loss: 0.571, val acc: 0.750 (best 0.750), test acc: 0.667 (best 0.667)\n",
            "In epoch 10, loss: 0.517, val acc: 0.750 (best 0.750), test acc: 0.667 (best 0.667)\n",
            "In epoch 15, loss: 0.427, val acc: 0.750 (best 0.750), test acc: 0.667 (best 0.667)\n",
            "In epoch 20, loss: 0.314, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 25, loss: 0.201, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 30, loss: 0.112, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 35, loss: 0.059, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 40, loss: 0.031, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 45, loss: 0.017, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 50, loss: 0.011, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 55, loss: 0.008, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 60, loss: 0.006, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 65, loss: 0.004, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 70, loss: 0.004, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 75, loss: 0.003, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 80, loss: 0.003, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 85, loss: 0.003, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 90, loss: 0.002, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n",
            "In epoch 95, loss: 0.002, val acc: 0.750 (best 0.750), test acc: 1.000 (best 0.667)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_2 = g.to('cuda')"
      ],
      "metadata": {
        "id": "FpYWEPaokwAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g.device, g_2.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5xtKRWBmQWn",
        "outputId": "42e610d3-d4ab-43a2-e168-196483e02430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), device(type='cuda', index=0))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = torch.stack(g_2.edges())\n",
        "indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVgwApv2hMic",
        "outputId": "d929e251-7b62-48a7-824a-a44889ee11d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 1, 1, 0, 1, 2, 3],\n",
              "        [1, 2, 3, 3, 3, 0, 1, 2, 3]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = g_2.num_nodes()\n",
        "A = dglsp.spmatrix(indices, shape=(N, N))\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYZdrroGhMgP",
        "outputId": "f689e023-f573-4390-d0e8-e119ea40af32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseMatrix(indices=tensor([[0, 0, 0, 1, 1, 0, 1, 2, 3],\n",
              "                             [1, 2, 3, 3, 3, 0, 1, 2, 3]], device='cuda:0'),\n",
              "             values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'),\n",
              "             shape=(4, 4), nnz=9)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5bkagqipga7",
        "outputId": "d2fd00cd-9b84-4eea-8783-ea93c03419e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# identity need manully move to device\n",
        "dglsp.identity(A.shape), dglsp.identity(A.shape).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWw5AuIGo6e8",
        "outputId": "882dd731-649e-41d6-f301-84db0a9df12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(SparseMatrix(indices=tensor([[0, 1, 2, 3],\n",
              "                              [0, 1, 2, 3]]),\n",
              "              values=tensor([1., 1., 1., 1.]),\n",
              "              shape=(4, 4), nnz=4),\n",
              " SparseMatrix(indices=tensor([[0, 1, 2, 3],\n",
              "                              [0, 1, 2, 3]], device='cuda:0'),\n",
              "              values=tensor([1., 1., 1., 1.], device='cuda:0'),\n",
              "              shape=(4, 4), nnz=4))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMYlNfN3mKa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dgl message passing"
      ],
      "metadata": {
        "id": "xaD0LtlslFMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multigraph test\n",
        "import os\n",
        "import dgl\n",
        "import dgl.data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl.nn import GraphConv\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "u, v = torch.tensor([0, 0, 0, 1, 1]), torch.tensor([1, 2, 3, 3, 3])\n",
        "g = dgl.graph((u, v))\n",
        "print(g)\n",
        "print(g.nodes())\n",
        "print(g.edges())\n",
        "print(g.edges(form='all'))\n",
        "g = dgl.graph((u, v), num_nodes=4)\n",
        "\n",
        "g.ndata['feat']=torch.tensor(np.random.rand(4,20), dtype=torch.float32)\n",
        "g.ndata[\"label\"]=torch.tensor(np.random.randint(0,2,(4,)))\n",
        "g.ndata['train_mask']=torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)\n",
        "g.ndata['val_mask']=torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)\n",
        "g.ndata['test_mask']=torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)\n",
        "g = dgl.add_self_loop(g)\n",
        "\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features = g.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    val_mask = g.ndata[\"val_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "    for e in range(100):\n",
        "        # Forward\n",
        "        logits = model(g, features)\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that you should only compute the losses of the nodes in the training set.\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test accuracy.\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print(\n",
        "                f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
        "            )\n",
        "\n",
        "# # train on cpu\n",
        "# model = GCN(g.ndata[\"feat\"].shape[1], 16, 2)\n",
        "# train(g, model)\n",
        "\n",
        "# train on gpu\n",
        "g = g.to('cuda')\n",
        "model = GCN(g.ndata[\"feat\"].shape[1], 16, 2).to('cuda')\n",
        "train(g, model)\n"
      ],
      "metadata": {
        "id": "75yQY4B_ZENy",
        "outputId": "ee9d5bdf-cc3f-45b3-e15e-cb995ed0e632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=4, num_edges=5,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={})\n",
            "tensor([0, 1, 2, 3])\n",
            "(tensor([0, 0, 0, 1, 1]), tensor([1, 2, 3, 3, 3]))\n",
            "(tensor([0, 0, 0, 1, 1]), tensor([1, 2, 3, 3, 3]), tensor([0, 1, 2, 3, 4]))\n",
            "In epoch 0, loss: 0.796, val acc: 0.667 (best 0.667), test acc: 1.000 (best 1.000)\n",
            "In epoch 5, loss: 0.591, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 10, loss: 0.493, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 15, loss: 0.409, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 20, loss: 0.330, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 25, loss: 0.259, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 30, loss: 0.198, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 35, loss: 0.149, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 40, loss: 0.111, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 45, loss: 0.084, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 50, loss: 0.064, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 55, loss: 0.050, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 60, loss: 0.039, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 65, loss: 0.032, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 70, loss: 0.026, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 75, loss: 0.022, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 80, loss: 0.019, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 85, loss: 0.017, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 90, loss: 0.015, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n",
            "In epoch 95, loss: 0.013, val acc: 0.333 (best 1.000), test acc: 0.000 (best 1.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ErzQem_ZA2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test pyG on gpu"
      ],
      "metadata": {
        "id": "NdrRm_iK9kvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch_geometric.datasets import Planetoid\n",
        "# from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "\n",
        "# print()\n",
        "# print(f'Dataset: {dataset}:')\n",
        "# print('======================')\n",
        "# print(f'Number of graphs: {len(dataset)}')\n",
        "# print(f'Number of features: {dataset.num_features}')\n",
        "# print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "# data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "# print()\n",
        "# print(data)\n",
        "# print('===========================================================================================================')\n",
        "\n",
        "# # Gather some statistics about the graph.\n",
        "# print(f'Number of nodes: {data.num_nodes}')\n",
        "# print(f'Number of edges: {data.num_edges}')\n",
        "# print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "# print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "# print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "# print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "# print(f'Has self-loops: {data.has_self_loops()}')\n",
        "# print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "id": "ZWIfHOiR9uLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "edge_index = torch.tensor([[0, 0, 0, 1],\n",
        "                           [1, 2, 3, 3]], dtype=torch.long)\n",
        "\n",
        "feat = torch.tensor(np.random.rand(4,20), dtype=torch.float32)\n",
        "label = torch.tensor(np.random.randint(0,2,(4,)))\n",
        "\n",
        "data = Data(x=feat, edge_index=edge_index, y=label)\n",
        "data.num_classes=2\n",
        "\n",
        "\n",
        "data.train_mask = torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)\n",
        "data.val_mask = torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)\n",
        "data.test_mask = torch.tensor(np.random.randint(0,2,(4,)), dtype=torch.bool)"
      ],
      "metadata": {
        "id": "XrSR4IeS--3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhUFnknPAW-w",
        "outputId": "54dca42b-7f25-4255-edc5-23fbad9a137f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[4, 20], edge_index=[2, 4], y=[4], num_classes=2, train_mask=[4], val_mask=[4], test_mask=[4])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.node_attrs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNkvzyxcBkvA",
        "outputId": "9e02a053-b1b4-4671-cec5-d04d88e150fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_mask', 'x', 'val_mask', 'y', 'test_mask']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.num_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yqXmSjJBqcb",
        "outputId": "85683388-2930-478a-8249-1e4ea4f77384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.conv1 = GCNConv(data.num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, data.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=16)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uu1H9909maG",
        "outputId": "a5f2659d-3b1c-4698-f393-3e025bf23b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(20, 16)\n",
            "  (conv2): GCNConv(16, 2)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(hidden_channels=16)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "      model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss\n",
        "\n",
        "\n",
        "# # train on cpu\n",
        "# for epoch in range(1, 5):\n",
        "#     loss = train()\n",
        "#     print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "\n",
        "# train on gpu\n",
        "data = data.to('cuda')\n",
        "model = model.to('cuda')\n",
        "for epoch in range(1, 5):\n",
        "    loss = train()\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKqVrbdK9nNO",
        "outputId": "c84a1bca-7289-470b-ed0b-b401602ba2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 1.3099\n",
            "Epoch: 002, Loss: 1.4581\n",
            "Epoch: 003, Loss: 0.9178\n",
            "Epoch: 004, Loss: 0.7099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKhmERXUETf_",
        "outputId": "c16826f5-c181-412b-eb7e-afe9b0c5be9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lf8r2XgSgwhM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}